# ğŸ‡©ğŸ‡ª German Legal AI - Single Cell Trainer (Copy this entire cell to Colab)

import subprocess
import sys
import os
import time
from datetime import datetime

print("ğŸ‡©ğŸ‡ª German Legal AI - Single Cell Training")
print("=" * 50)

# Step 1: Install packages
print("ğŸ“¦ Installing packages...")
packages = [
    "numpy==1.24.3",
    "torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121",
    "transformers==4.35.2",
    "datasets==2.14.6", 
    "accelerate==0.24.1",
    "peft==0.6.2",
    "bitsandbytes==0.41.2.post2",
    "huggingface_hub==0.17.3",
    "pandas==1.5.3"
]

for package in packages:
    print(f"Installing {package.split('==')[0]}...")
    result = subprocess.run([sys.executable, "-m", "pip", "install", "-q"] + package.split(), 
                          capture_output=True, text=True)

print("âœ… Packages installed")

# Step 2: Import and check environment
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling
from peft import LoraConfig, get_peft_model, TaskType
from datasets import Dataset
import pandas as pd
import json
import zipfile

print(f"âœ… NumPy: {np.__version__}")
print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… CUDA: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")

# Step 3: Login to HuggingFace (if needed)
from huggingface_hub import notebook_login
print("ğŸ” Please log in to HuggingFace (press Enter if already logged in):")
try:
    notebook_login()
except:
    print("âš ï¸ Login skipped - using public models only")

# Step 4: Create German legal dataset
print("ğŸ“Š Creating German legal dataset...")
data = [
    {
        "instruction": "Analysiere die rechtlichen Probleme bei einer Ã¼berhÃ¶hten Mietkaution.",
        "input": "Der Vermieter verlangt eine Kaution von 5 Monatsmieten bei einer Wohnung mit 1.200 Euro Monatsmiete.",
        "output": "Die geforderte Kaution von 5 Monatsmieten (6.000 Euro) verstÃ¶ÃŸt gegen Â§ 551 BGB. Nach deutschem Mietrecht ist die Kaution auf maximal 3 Monatsmieten begrenzt. Die rechtlich zulÃ¤ssige HÃ¶chstkaution betrÃ¤gt daher 3.600 Euro. Der Mieter kann die Zahlung der Ã¼berschÃ¼ssigen 2.400 Euro verweigern."
    },
    {
        "instruction": "Bewerte die RechtmÃ¤ÃŸigkeit einer KÃ¼ndigung in der Probezeit.",
        "input": "Ein Arbeitnehmer wird nach 8 Monaten gekÃ¼ndigt. Im Arbeitsvertrag ist eine Probezeit von 12 Monaten vereinbart.",
        "output": "Die vereinbarte Probezeit von 12 Monaten ist nach Â§ 622 Abs. 3 BGB unzulÃ¤ssig, da die gesetzliche HÃ¶chstdauer von 6 Monaten Ã¼berschritten wird. Die KÃ¼ndigung nach 8 Monaten erfolgte auÃŸerhalb der zulÃ¤ssigen Probezeit und kÃ¶nnte unwirksam sein."
    },
    {
        "instruction": "ErklÃ¤re die GewÃ¤hrleistungsrechte beim Gebrauchtwagenkauf.",
        "input": "Ein KÃ¤ufer entdeckt nach 3 Wochen einen nicht offenbarten Unfallschaden am gekauften Gebrauchtwagen.",
        "output": "Der KÃ¤ufer hat GewÃ¤hrleistungsrechte nach Â§Â§ 437 ff. BGB. Bei einem nicht offenbarten Unfallschaden liegt ein Sachmangel vor. Der KÃ¤ufer kann zunÃ¤chst NacherfÃ¼llung verlangen, dann Minderung oder RÃ¼cktritt wÃ¤hlen. Bei arglistiger TÃ¤uschung ist eine Anfechtung nach Â§ 123 BGB mÃ¶glich."
    },
    {
        "instruction": "Analysiere die Haftung eines GmbH-GeschÃ¤ftsfÃ¼hrers bei Insolvenzverschleppung.",
        "input": "Ein GeschÃ¤ftsfÃ¼hrer hat trotz Ãœberschuldung weitere Verbindlichkeiten eingegangen.",
        "output": "Der GeschÃ¤ftsfÃ¼hrer hat seine Pflichten nach Â§Â§ 15a, 64 InsO verletzt. Bei Ãœberschuldung muss unverzÃ¼glich ein Insolvenzantrag gestellt werden. Er macht sich nach Â§ 15a Abs. 4 InsO schadensersatzpflichtig und riskiert strafrechtliche Verfolgung wegen Insolvenzverschleppung."
    },
    {
        "instruction": "Bewerte einen Nachbarschaftsstreit wegen LÃ¤rmbelÃ¤stigung.",
        "input": "Nachbar A spielt tÃ¤glich von 22:00 bis 24:00 Uhr laute Musik. Nachbar B fÃ¼hlt sich gestÃ¶rt.",
        "output": "Nachbar B hat AnsprÃ¼che nach Â§ 1004 BGB. Nach Ã¼blichen Hausordnungen beginnt die Nachtruhe um 22:00 Uhr. Laute Musik danach stellt eine unzumutbare StÃ¶rung dar, die Ã¼ber das nach Â§ 906 BGB hinzunehmende MaÃŸ hinausgeht. Nachbar B kann Unterlassung verlangen."
    },
    {
        "instruction": "ErklÃ¤re die rechtlichen Grundlagen eines Kaufvertrags nach BGB.",
        "input": "Welche wesentlichen Elemente muss ein Kaufvertrag enthalten?",
        "output": "Ein Kaufvertrag nach Â§Â§ 433 ff. BGB benÃ¶tigt: 1) Einigung Ã¼ber die Kaufsache, 2) Einigung Ã¼ber den Kaufpreis, 3) Zwei Ã¼bereinstimmende WillenserklÃ¤rungen. Der VerkÃ¤ufer verpflichtet sich zur Ãœbereignung, der KÃ¤ufer zur Zahlung. Wichtige Aspekte sind GewÃ¤hrleistung und GefahrÃ¼bergang."
    }
]

def format_instruction(example):
    if example.get('input', '').strip():
        text = f"### Anweisung:\n{example['instruction']}\n\n### Eingabe:\n{example['input']}\n\n### Antwort:\n{example['output']}<|endoftext|>"
    else:
        text = f"### Anweisung:\n{example['instruction']}\n\n### Antwort:\n{example['output']}<|endoftext|>"
    return {"text": text}

df = pd.DataFrame(data)
dataset = Dataset.from_pandas(df)
dataset = dataset.map(format_instruction)
dataset = dataset.train_test_split(test_size=0.2, seed=42)
train_dataset, eval_dataset = dataset['train'], dataset['test']

print(f"âœ… Dataset: {len(train_dataset)} train, {len(eval_dataset)} test")

# Step 5: Load model
print("ğŸ¤– Loading model...")
model_candidates = ['microsoft/DialoGPT-medium', 'DiscoResearch/DiscoLM_German_7b_v1']

model_name = None
for candidate in model_candidates:
    try:
        tokenizer = AutoTokenizer.from_pretrained(candidate)
        model_name = candidate
        print(f"âœ… Using: {model_name}")
        break
    except:
        continue

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right"

quantization_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=6.0)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quantization_config,
    device_map="auto",
    trust_remote_code=True,
    torch_dtype=torch.float16
)
model.gradient_checkpointing_enable()

print(f"âœ… Model loaded: {model.num_parameters():,} parameters")

# Step 6: Apply LoRA
print("ğŸ›ï¸ Applying LoRA...")
target_modules = ["c_attn", "c_proj"] if "DialoGPT" in model_name else ["q_proj", "v_proj", "k_proj", "o_proj"]

lora_config = LoraConfig(
    r=8, lora_alpha=16, target_modules=target_modules,
    lora_dropout=0.1, bias="none", task_type=TaskType.CAUSAL_LM
)
model = get_peft_model(model, lora_config)

trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
total = sum(p.numel() for p in model.parameters())
print(f"âœ… LoRA: {trainable:,} trainable ({100*trainable/total:.2f}%)")

# Step 7: Prepare training
print("ğŸ”¤ Tokenizing...")
def tokenize_function(examples):
    return tokenizer(examples["text"], truncation=True, padding=False, max_length=1024)

tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)
tokenized_eval = eval_dataset.map(tokenize_function, batched=True, remove_columns=eval_dataset.column_names)

output_dir = "./german-legal-model"
training_args = TrainingArguments(
    output_dir=output_dir, overwrite_output_dir=True, num_train_epochs=2,
    per_device_train_batch_size=1, gradient_accumulation_steps=8,
    learning_rate=5e-5, fp16=True, gradient_checkpointing=True,
    logging_steps=5, eval_steps=10, evaluation_strategy="steps",
    save_steps=20, save_total_limit=2, remove_unused_columns=False, report_to=None
)

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)
trainer = Trainer(
    model=model, args=training_args, train_dataset=tokenized_train,
    eval_dataset=tokenized_eval, data_collator=data_collator, tokenizer=tokenizer
)

# Step 8: Train
print("ğŸ‹ï¸ Starting training...")
torch.cuda.empty_cache()
start_time = time.time()

try:
    training_result = trainer.train()
    training_time = time.time() - start_time
    
    print(f"âœ… Training completed in {training_time/60:.1f} minutes")
    print(f"ğŸ“Š Final loss: {training_result.training_loss:.4f}")
    
    trainer.save_model()
    tokenizer.save_pretrained(output_dir)
    
except Exception as e:
    print(f"âŒ Training failed: {str(e)}")
    try:
        trainer.save_model(f"{output_dir}-partial")
        print("ğŸ’¾ Partial model saved")
    except:
        pass

# Step 9: Test model
print("ğŸ§ª Testing model...")
def generate_response(instruction, input_text=""):
    if input_text.strip():
        prompt = f"### Anweisung:\n{instruction}\n\n### Eingabe:\n{input_text}\n\n### Antwort:\n"
    else:
        prompt = f"### Anweisung:\n{instruction}\n\n### Antwort:\n"
    
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=150, temperature=0.7, do_sample=True, top_p=0.9)
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response[len(prompt):].strip()

tests = [
    ("ErklÃ¤re rechtliche Probleme bei Ã¼berhÃ¶hter Mietkaution.", "Vermieter fordert 4 Monatsmieten."),
    ("Was sind KÃ¤uferrechte bei mangelhaftem Auto?", ""),
    ("Bewerte KÃ¼ndigung in Probezeit.", "Nach 10 Monaten, bei 12 Monaten Probezeit.")
]

for i, (instruction, input_text) in enumerate(tests, 1):
    print(f"\nğŸ” Test {i}: {instruction[:40]}...")
    try:
        response = generate_response(instruction, input_text)
        print(f"ğŸ“ Response: {response[:150]}...")
    except Exception as e:
        print(f"âŒ Test failed: {str(e)[:50]}...")

# Step 10: Create deployment package
print("ğŸ“¦ Creating deployment package...")
config = {
    "model_info": {"name": "German Legal AI", "base_model": model_name, "version": "1.0", "training_date": datetime.now().isoformat()},
    "inference_config": {"max_new_tokens": 256, "temperature": 0.7, "top_p": 0.9}
}

with open(f"{output_dir}/config.json", "w") as f:
    json.dump(config, f, indent=2)

zip_name = f"german-legal-ai-{datetime.now().strftime('%Y%m%d-%H%M')}.zip"
with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
    for root, dirs, files in os.walk(output_dir):
        for file in files:
            file_path = os.path.join(root, file)
            arcname = os.path.relpath(file_path, output_dir)
            zipf.write(file_path, arcname)

print(f"\nğŸ‰ German Legal AI training completed!")
print(f"ğŸ“¦ Download: {zip_name}")
print(f"ğŸš€ Ready for deployment on AX102!")
print(f"â±ï¸ Total time: {(time.time() - start_time)/60:.1f} minutes")